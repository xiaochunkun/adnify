/**
 * æƒ…ç»ªç¯å¢ƒé€‚é…æœåŠ¡
 * æ ¹æ®æƒ…ç»ªçŠ¶æ€è‡ªåŠ¨è°ƒæ•´ç¼–è¾‘å™¨ç¯å¢ƒ
 */

import { EventBus } from '../core/EventBus'
import { logger } from '@utils/Logger'
import type {
  EmotionState,
  EmotionDetection,
  EnvironmentAdaptation,
} from '../types/emotion'

// é»˜è®¤é€‚é…é…ç½®
const DEFAULT_ADAPTATIONS: Record<EmotionState, EnvironmentAdaptation> = {
  focused: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#3b82f6',
    },
    ui: {
      notifications: 'minimal',
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'suggestive',
      tone: 'neutral',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: false,
      volume: 0,
      type: 'none',
    },
    break: {
      suggestBreak: false,
      breakInterval: 90 * 60 * 1000, // 90åˆ†é’Ÿ
      microBreaks: false,
    },
  },
  
  frustrated: {
    theme: {
      id: 'adnify-dark',
      brightness: 'dim',
      accentColor: '#f97316', // æ¸©æš–çš„æ©™è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 15, // ç¨å¤§å­—ä½“å‡å°‘å‹åŠ›
      lineHeight: 1.6,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'high',
    },
    sound: {
      enabled: true,
      volume: 0.3,
      type: 'relax',
    },
    break: {
      suggestBreak: true,
      breakInterval: 15 * 60 * 1000, // 15åˆ†é’Ÿå»ºè®®ä¼‘æ¯
      microBreaks: true,
    },
  },
  
  tired: {
    theme: {
      id: 'adnify-dark',
      brightness: 'dim', // é™ä½äº®åº¦
      accentColor: '#8b5cf6', // æŸ”å’Œçš„ç´«è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 16, // æ›´å¤§å­—ä½“
      lineHeight: 1.7,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'low', // å‡å°‘å¹²æ‰°
    },
    sound: {
      enabled: true,
      volume: 0.2,
      type: 'energize',
    },
    break: {
      suggestBreak: true,
      breakInterval: 30 * 60 * 1000, // 30åˆ†é’Ÿ
      microBreaks: true,
    },
  },
  
  excited: {
    theme: {
      id: 'adnify-dark',
      brightness: 'bright',
      accentColor: '#22c55e', // æ˜äº®çš„ç»¿è‰²
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'fast',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'passive', // ä¸æ‰“æ‰°åˆ›æ„
      tone: 'neutral',
      suggestionFrequency: 'low',
    },
    sound: {
      enabled: true,
      volume: 0.4,
      type: 'focus',
    },
    break: {
      suggestBreak: false,
      breakInterval: 120 * 60 * 1000,
      microBreaks: false,
    },
  },
  
  bored: {
    theme: {
      id: 'cyberpunk',
      brightness: 'bright',
      accentColor: '#ec4899', // é²œè‰³çš„ç²‰è‰²
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'fast',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'high', // å¤šç»™å»ºè®®
    },
    sound: {
      enabled: true,
      volume: 0.5,
      type: 'energize',
    },
    break: {
      suggestBreak: true,
      breakInterval: 45 * 60 * 1000,
      microBreaks: true,
    },
  },
  
  stressed: {
    theme: {
      id: 'midnight',
      brightness: 'dim',
      accentColor: '#06b6d4', // å†·é™çš„é’è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 15,
      lineHeight: 1.6,
    },
    ai: {
      proactivity: 'active',
      tone: 'direct',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: true,
      volume: 0.25,
      type: 'relax',
    },
    break: {
      suggestBreak: true,
      breakInterval: 20 * 60 * 1000,
      microBreaks: true,
    },
  },
  
  flow: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#6366f1', // é›è“
    },
    ui: {
      notifications: 'disabled', // å®Œå…¨æ— å¹²æ‰°
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'passive', // ç»ä¸æ‰“æ‰°
      tone: 'neutral',
      suggestionFrequency: 'low',
    },
    sound: {
      enabled: true,
      volume: 0.3,
      type: 'focus',
    },
    break: {
      suggestBreak: false, // ä¸æ‰“æ‰°å¿ƒæµ
      breakInterval: 150 * 60 * 1000, // 2.5å°æ—¶
      microBreaks: true, // ä½†å»ºè®®å¾®ä¼‘æ¯
    },
  },
  
  neutral: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#3b82f6',
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'suggestive',
      tone: 'neutral',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: false,
      volume: 0,
      type: 'none',
    },
    break: {
      suggestBreak: true,
      breakInterval: 60 * 60 * 1000,
      microBreaks: true,
    },
  },
}

// æƒ…ç»ªå¯¹åº”çš„æç¤ºæ¶ˆæ¯
const EMOTION_MESSAGES: Record<EmotionState, string[]> = {
  focused: [
    'ä¿æŒä¸“æ³¨ï¼Œä½ æ­£åœ¨é«˜æ•ˆå·¥ä½œ ğŸ’ª',
    'è‰¯å¥½çš„èŠ‚å¥ï¼Œç»§ç»­ä¿æŒ',
    'ä¸“æ³¨æ¨¡å¼å·²å¯åŠ¨',
  ],
  frustrated: [
    'é‡åˆ°å›°éš¾äº†å—ï¼Ÿæ·±å‘¼å¸ï¼Œä¸€æ­¥æ­¥æ¥ ğŸŒ±',
    'æ¯ä¸ª bug éƒ½æ˜¯æˆé•¿çš„æœºä¼š',
    'éœ€è¦æˆ‘å¸®ä½ åˆ†æä¸€ä¸‹å—ï¼Ÿ',
    'ä¼‘æ¯ä¸€ä¸‹ï¼Œæ¢ä¸ªæ€è·¯å¯èƒ½ä¼šæ›´å¥½',
  ],
  tired: [
    'çœ‹èµ·æ¥æœ‰ç‚¹ç´¯äº†ï¼Œå–æ¯æ°´ä¼‘æ¯ä¸€ä¸‹å§ â˜•',
    'é•¿æ—¶é—´å·¥ä½œä¼šé™ä½æ•ˆç‡ï¼Œå»ºè®®ä¼‘æ¯',
    'ä½ çš„çœ¼ç›éœ€è¦æ”¾æ¾äº†ï¼Œçœ‹çœ‹è¿œå¤„',
  ],
  excited: [
    'å……æ»¡èƒ½é‡ï¼ä¿æŒè¿™ä¸ªçŠ¶æ€ ğŸš€',
    'çµæ„Ÿçˆ†å‘æ—¶åˆ»ï¼Œè®°å½•ä¸‹æ¥',
    'åˆ›é€ åŠ›æ»¡æ»¡ï¼Œç»§ç»­ä¿æŒï¼',
  ],
  bored: [
    'çœ‹èµ·æ¥æœ‰ç‚¹æ— èŠï¼Œè¯•è¯•é‡æ„è¿™æ®µä»£ç ï¼Ÿ ğŸ¤”',
    'è¦ä¸è¦å°è¯•ä¸€ä¸ªæ–°çš„å®ç°æ–¹å¼ï¼Ÿ',
    'ä¼‘æ¯ä¸€ä¸‹ï¼Œåšç‚¹æœ‰è¶£çš„äº‹æƒ…',
  ],
  stressed: [
    'å‹åŠ›æœ‰ç‚¹å¤§ï¼Œæ·±å‘¼å¸æ”¾æ¾ä¸€ä¸‹ ğŸ§˜',
    'ä¼˜å…ˆçº§æ’åºï¼Œä¸€ä»¶ä¸€ä»¶æ¥',
    'ä½ å·²ç»åšå¾—å¾ˆå¥½äº†ï¼Œä¸è¦ç»™è‡ªå·±å¤ªå¤§å‹åŠ›',
    'éœ€è¦æˆ‘å¸®ä½ æ•´ç†ä¸€ä¸‹æ€è·¯å—ï¼Ÿ',
  ],
  flow: [
    'è¿›å…¥å¿ƒæµçŠ¶æ€ï¼Œäº«å—ç¼–ç çš„ä¹è¶£ âœ¨',
    'å®Œç¾çš„å¿ƒæµï¼Œç»§ç»­ä¿æŒ',
    'ä½ æ­£åœ¨åˆ›é€ ä¼Ÿå¤§çš„ä»£ç ',
  ],
  neutral: [],
}

class EmotionAdapter {
  private currentAdaptation: EnvironmentAdaptation | null = null
  private breakTimer: NodeJS.Timeout | null = null
  private microBreakTimer: NodeJS.Timeout | null = null
  private audioContext: AudioContext | null = null
  private unsubscribeEmotionChanged: (() => void) | null = null
  /** è·Ÿè¸ªæ‰€æœ‰å¾…æ‰§è¡Œçš„ setTimeoutï¼Œcleanup æ—¶ç»Ÿä¸€æ¸…ç† */
  private pendingTimeouts: NodeJS.Timeout[] = []
  /** å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘æº */
  private currentAudioSource: AudioBufferSourceNode | HTMLAudioElement | null = null
  /** å½“å‰éŸ³é¢‘çš„å¢ç›ŠèŠ‚ç‚¹ */
  private currentGainNode: GainNode | null = null

  /**
   * åˆå§‹åŒ–é€‚é…å™¨ï¼ˆé˜²é‡å…¥ï¼‰
   */
  initialize(): void {
    // å¦‚æœå·²ç»åˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›
    if (this.unsubscribeEmotionChanged) {
      return
    }

    // ç¯å¢ƒéŸ³æ•ˆå·²ç¦ç”¨ï¼šå¯åŠ¨æ—¶å…ˆåœæ‰ä»»ä½•å¯èƒ½æ®‹ç•™çš„èƒŒæ™¯éŸ³
    this.stopAmbientSound()

    // è®¢é˜…æƒ…ç»ªå˜åŒ–äº‹ä»¶
    this.unsubscribeEmotionChanged = EventBus.on('emotion:changed', (event) => {
      if (event.emotion) {
        this.adaptToEmotion(event.emotion)
      }
    })

    logger.agent.info('[EmotionAdapter] Initialized')
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup(): void {
    // å–æ¶ˆäº‹ä»¶è®¢é˜…
    if (this.unsubscribeEmotionChanged) {
      this.unsubscribeEmotionChanged()
      this.unsubscribeEmotionChanged = null
    }

    // æ¸…ç†å®šæ—¶å™¨
    if (this.breakTimer) {
      clearInterval(this.breakTimer)
      this.breakTimer = null
    }
    if (this.microBreakTimer) {
      clearInterval(this.microBreakTimer)
      this.microBreakTimer = null
    }

    // æ¸…ç†æ‰€æœ‰å¾…æ‰§è¡Œçš„ setTimeoutï¼ˆæ¶ˆæ¯å»¶è¿Ÿå‘é€ã€éŸ³é¢‘è‡ªåŠ¨åœæ­¢ç­‰ï¼‰
    for (const t of this.pendingTimeouts) clearTimeout(t)
    this.pendingTimeouts = []

    // åœæ­¢ç¯å¢ƒéŸ³
    this.stopAmbientSound()

    logger.agent.info('[EmotionAdapter] Cleaned up')
  }

  /**
   * æ ¹æ®æƒ…ç»ªé€‚é…ç¯å¢ƒ
   */
  adaptToEmotion(detection: EmotionDetection): void {
    const adaptation = DEFAULT_ADAPTATIONS[detection.state]
    this.currentAdaptation = adaptation

    // åº”ç”¨å„é¡¹é€‚é…
    this.applyThemeAdaptation(adaptation.theme)
    this.applyUIAdaptation(adaptation.ui)
    this.applyAIAdaptation(adaptation.ai, detection)
    this.applySoundAdaptation(adaptation.sound)
    this.setupBreakReminders(adaptation.break, detection.state)

    // æ˜¾ç¤ºæƒ…ç»ªæ„ŸçŸ¥æç¤º
    this.showEmotionAwareness(detection)

    logger.agent.info('[EmotionAdapter] Adapted to:', detection.state)
  }

  /**
   * æ‰‹åŠ¨åº”ç”¨ç‰¹å®šæƒ…ç»ªçš„é€‚é…
   */
  forceAdapt(state: EmotionState): void {
    const mockDetection: EmotionDetection = {
      state,
      intensity: 0.8,
      confidence: 1,
      triggeredAt: Date.now(),
      duration: 0,
      factors: [],
    }
    this.adaptToEmotion(mockDetection)
  }

  // ===== ç§æœ‰é€‚é…æ–¹æ³• =====

  private applyThemeAdaptation(theme: EnvironmentAdaptation['theme']): void {
    // åˆ‡æ¢ä¸»é¢˜ï¼ˆç®€åŒ–å®ç°ï¼‰
    // const store = useStore.getState()

    // åº”ç”¨äº®åº¦è°ƒæ•´ï¼ˆé€šè¿‡ CSS å˜é‡ï¼‰
    const root = document.documentElement
    const brightnessMap = {
      dim: '0.85',
      normal: '1',
      bright: '1.1',
    }
    root.style.setProperty('--editor-brightness', brightnessMap[theme.brightness])
    
    // è®¾ç½®å¼ºè°ƒè‰²
    root.style.setProperty('--custom-accent', theme.accentColor)
  }

  private applyUIAdaptation(ui: EnvironmentAdaptation['ui']): void {
    // å­—ä½“å¤§å°ï¼ˆç®€åŒ–å®ç°ï¼‰
    // const store = useStore.getState()

    // åŠ¨ç”»é€Ÿåº¦ï¼ˆé€šè¿‡ CSS å˜é‡ï¼‰
    const root = document.documentElement
    const speedMap = {
      slow: '0.5s',
      normal: '0.2s',
      fast: '0.1s',
    }
    root.style.setProperty('--transition-duration', speedMap[ui.animationSpeed])

    // é€šçŸ¥è®¾ç½®ï¼ˆç®€åŒ–å®ç°ï¼‰
    // store.updateSettings?.({
    //   notifications: ui.notifications,
    // })
  }

  private applyAIAdaptation(
    _ai: EnvironmentAdaptation['ai'],
    detection: EmotionDetection
  ): void {
    const state = detection.state

    // å¿ƒæµ / ä¸­æ€§çŠ¶æ€ä¸å‘æ¶ˆæ¯
    if (state === 'neutral' || state === 'flow') return

    // ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡åˆ†æå™¨äº§ç”Ÿçš„çœŸå®å»ºè®®
    const contextSuggestions = detection.suggestions || []
    if (contextSuggestions.length > 0) {
      const t = setTimeout(() => {
        EventBus.emit({
          type: 'emotion:message',
          message: contextSuggestions[0],
          state,
        })
      }, 2000)
      this.pendingTimeouts.push(t)
      return
    }

    // æ²¡æœ‰ä¸Šä¸‹æ–‡å»ºè®®æ—¶é€€å›åˆ°é€šç”¨æ¶ˆæ¯
    const messages = EMOTION_MESSAGES[state]
    if (messages.length > 0) {
      const randomIndex = Math.floor(Math.random() * messages.length)
      const message = messages[randomIndex]
      const t = setTimeout(() => {
        EventBus.emit({
          type: 'emotion:message',
          message,
          state,
        })
      }, 3000)
      this.pendingTimeouts.push(t)
    }
  }

  /** ç¯å¢ƒéŸ³æ•ˆåŠŸèƒ½å·²ç¦ç”¨ï¼Œæš‚ä¸å¼€å‘ */
  private readonly AMBIENT_SOUND_ENABLED = false

  private applySoundAdaptation(_sound: EnvironmentAdaptation['sound']): void {
    this.stopAmbientSound()
    // ç¯å¢ƒéŸ³æ•ˆå·²å…³é—­ï¼Œä¸å†è°ƒç”¨ä»»ä½•æ’­æ”¾é€»è¾‘
  }

  private setupBreakReminders(
    breakConfig: EnvironmentAdaptation['break'],
    state: EmotionState
  ): void {
    // æ¸…é™¤ä¹‹å‰çš„è®¡æ—¶å™¨
    if (this.breakTimer) {
      clearInterval(this.breakTimer)
      this.breakTimer = null
    }
    if (this.microBreakTimer) {
      clearInterval(this.microBreakTimer)
      this.microBreakTimer = null
    }

    if (!breakConfig.suggestBreak) return

    // è®¾ç½®å¾®ä¼‘æ¯æé†’ï¼ˆæ¯20åˆ†é’Ÿï¼‰
    if (breakConfig.microBreaks) {
      this.microBreakTimer = setInterval(() => {
        EventBus.emit({
          type: 'break:micro',
          message: 'çœ¼ç›ç–²åŠ³äº†å—ï¼Ÿçœ‹çœ‹è¿œå¤„20ç§’ ğŸ‘€',
        })
      }, 20 * 60 * 1000)
    }

    // è®¾ç½®æ­£å¼ä¼‘æ¯æé†’
    this.breakTimer = setInterval(() => {
      const messages: Record<EmotionState, string> = {
        focused: 'ä½ å·²ç»ä¸“æ³¨å·¥ä½œå¾ˆä¹…äº†ï¼Œèµ·æ¥æ´»åŠ¨ä¸€ä¸‹å§ ğŸš¶',
        frustrated: 'å¡ä½äº†ï¼Ÿä¼‘æ¯ä¸€ä¸‹å¯èƒ½ä¼šæœ‰æ–°æ€è·¯ ğŸ’¡',
        tired: 'è¯¥ä¼‘æ¯ä¸€ä¸‹äº†ï¼Œå……ç”µåæ•ˆç‡ä¼šæ›´é«˜ âš¡',
        excited: 'ä¿æŒçƒ­æƒ…çš„åŒæ—¶ä¹Ÿè¦æ³¨æ„ä¼‘æ¯å“¦ â˜•',
        bored: 'ä¼‘æ¯ä¸€ä¸‹å§ï¼Œåšç‚¹æœ‰è¶£çš„äº‹æƒ… ğŸ®',
        stressed: 'å‹åŠ›å¤§æ—¶æ›´è¦ä¼‘æ¯ï¼Œæ·±å‘¼å¸æ”¾æ¾ä¸€ä¸‹ ğŸ§˜',
        flow: 'å¿ƒæµå¾ˆç¾å¥½ï¼Œä½†ä¹Ÿè®°å¾—ç…§é¡¾å¥½èº«ä½“ ğŸŒ¿',
        neutral: 'å·¥ä½œä¸€æ®µæ—¶é—´äº†ï¼Œä¼‘æ¯ä¸€ä¸‹å§ â˜•',
      }

      // ä¼‘æ¯å»ºè®®
      EventBus.emit({
        type: 'break:suggested',
        message: messages[state],
      })
    }, breakConfig.breakInterval)
  }

  private showEmotionAwareness(detection: EmotionDetection): void {
    // é€šè¿‡ toast æˆ–å†…è”æç¤ºæ˜¾ç¤ºæƒ…ç»ªæ£€æµ‹
    const emotionLabels: Record<EmotionState, string> = {
      focused: 'ä¸“æ³¨æ¨¡å¼',
      frustrated: 'æ£€æµ‹åˆ°æ²®ä¸§',
      tired: 'æ£€æµ‹åˆ°ç–²åŠ³',
      excited: 'èƒ½é‡æ»¡æ»¡',
      bored: 'æ£€æµ‹åˆ°æ— èŠ',
      stressed: 'æ£€æµ‹åˆ°å‹åŠ›',
      flow: 'å¿ƒæµçŠ¶æ€',
      neutral: 'å·¥ä½œæ¨¡å¼',
    }

    // ç®€åŒ– toast æç¤º
    console.log(`[Emotion] ${emotionLabels[detection.state]} - å¼ºåº¦: ${Math.round(detection.intensity * 100)}%`)
  }

  // è·å–æƒ…ç»ªå¯¹åº”çš„ toast ç±»å‹
  // private getEmotionVariant(state: EmotionState): string {...}

  // ===== ç¯å¢ƒéŸ³æ•ˆ =====

  /**
   * è½»éŸ³ä¹èµ„æº URL ï¼ï¼ï¼å¾…å®šå¼€å‘ï¼ï¼ï¼
   */
  private readonly MUSIC_URLS: Record<'focus' | 'relax' | 'energize', string[]> = {
    focus: [
      // ä¸“æ³¨éŸ³ä¹ - ä½¿ç”¨ Lofi æˆ– Ambient é£æ ¼
      // ç¤ºä¾‹ï¼šå¯ä»¥ä½¿ç”¨ Pixabay æˆ–å…¶ä»–å…è´¹èµ„æº
      // å¦‚æœç½‘ç»œèµ„æºä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨å›é€€åˆ°ç”Ÿæˆçš„ç™½å™ªéŸ³
    ],
    relax: [
      // æ”¾æ¾éŸ³ä¹ - è‡ªç„¶å£°éŸ³æˆ–å†¥æƒ³éŸ³ä¹
    ],
    energize: [
      // æ¿€åŠ±éŸ³ä¹ - è½»å¿«çš„èƒŒæ™¯éŸ³ä¹
    ],
  }

  /**
   * è·å–éŸ³ä¹ URLï¼ˆæ”¯æŒä»è®¾ç½®ä¸­è¯»å–ç”¨æˆ·é…ç½®ï¼‰
   */
  private getMusicUrl(type: 'focus' | 'relax' | 'energize'): string | null {
    const urls = this.MUSIC_URLS[type]
    // ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ª URLï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› nullï¼ˆä¼šä½¿ç”¨å›é€€æ–¹æ¡ˆï¼‰
    return urls && urls.length > 0 ? urls[0] : null
  }

  /**
   * åŠ è½½å¹¶æ’­æ”¾ç½‘ç»œéŸ³é¢‘ï¼ˆç¯å¢ƒéŸ³æ•ˆå·²å…³é—­ï¼Œæ­¤æ–¹æ³•ä¸å†æ’­æ”¾ï¼‰
   */
  private async loadAndPlayAudio(url: string, volume: number): Promise<void> {
    if (!this.AMBIENT_SOUND_ENABLED) return
    try {
      // ä½¿ç”¨ HTMLAudioElement æ’­æ”¾ï¼ˆæ›´ç®€å•ï¼Œæ”¯æŒç½‘ç»œèµ„æºï¼‰
      const audio = new Audio(url)
      audio.loop = true
      audio.volume = volume * 0.3 // é™ä½éŸ³é‡ï¼Œæ›´èˆ’é€‚
      audio.preload = 'auto'

      // æ·¡å…¥æ•ˆæœ
      audio.volume = 0
      await audio.play()
      
      // æ·¡å…¥åŠ¨ç”»
      const fadeInDuration = 2000 // 2ç§’
      const startTime = Date.now()
      const targetVolume = volume * 0.3
      
      const fadeInterval = setInterval(() => {
        const elapsed = Date.now() - startTime
        if (elapsed >= fadeInDuration) {
          audio.volume = targetVolume
          clearInterval(fadeInterval)
        } else {
          audio.volume = (elapsed / fadeInDuration) * targetVolume
        }
      }, 50)

      this.currentAudioSource = audio
      this.currentGainNode = null // HTMLAudioElement ä¸ä½¿ç”¨ GainNode

      // é”™è¯¯å¤„ç†
      audio.addEventListener('error', () => {
        logger.agent.warn('[EmotionAdapter] Audio load failed, falling back to generated sound:', url)
        // å¦‚æœç½‘ç»œéŸ³é¢‘åŠ è½½å¤±è´¥ï¼Œå¯ä»¥å›é€€åˆ°ç”Ÿæˆçš„éŸ³æ•ˆ
        this.playFallbackSound(volume)
      })

    } catch (error) {
      logger.agent.error('[EmotionAdapter] Failed to play audio:', error)
      // å›é€€åˆ°ç”Ÿæˆçš„éŸ³æ•ˆ
      this.playFallbackSound(volume)
    }
  }

  /**
   * å›é€€æ–¹æ¡ˆï¼šå¦‚æœç½‘ç»œéŸ³é¢‘åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç”Ÿæˆçš„éŸ³æ•ˆï¼ˆç¯å¢ƒéŸ³æ•ˆå·²å…³é—­ï¼Œæ­¤æ–¹æ³•ä¸å†æ’­æ”¾ï¼‰
   */
  private playFallbackSound(volume: number): void {
    if (!this.AMBIENT_SOUND_ENABLED) return
    try {
      if (!this.audioContext) {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      }

      // ç”Ÿæˆç®€å•çš„ç™½å™ªéŸ³ï¼ˆæ¯”ä¹‹å‰çš„æ­£å¼¦æ³¢æ›´è‡ªç„¶ï¼‰
      const bufferSize = this.audioContext.sampleRate * 2
      const buffer = this.audioContext.createBuffer(1, bufferSize, this.audioContext.sampleRate)
      const data = buffer.getChannelData(0)
      
      for (let i = 0; i < bufferSize; i++) {
        data[i] = Math.random() * 2 - 1
      }

      const source = this.audioContext.createBufferSource()
      const gainNode = this.audioContext.createGain()
      const filter = this.audioContext.createBiquadFilter()

      source.buffer = buffer
      source.loop = true
      filter.type = 'lowpass'
      filter.frequency.value = 2000
      gainNode.gain.value = volume * 0.05

      source.connect(filter)
      filter.connect(gainNode)
      gainNode.connect(this.audioContext.destination)
      source.start(0)

      this.currentAudioSource = source
      this.currentGainNode = gainNode
    } catch (error) {
      logger.agent.error('[EmotionAdapter] Fallback sound failed:', error)
    }
  }

  private async playAmbientSound(
    _type: 'focus' | 'relax' | 'energize' | 'none',
    _volume: number
  ): Promise<void> {
    // ç¯å¢ƒéŸ³æ•ˆå·²å…³é—­ï¼šåªåœæ­¢ã€ä¸æ’­æ”¾
    this.stopAmbientSound()
  }

  private stopAmbientSound(): void {
    // åœæ­¢ HTMLAudioElement
    if (this.currentAudioSource instanceof HTMLAudioElement) {
      try {
        // æ·¡å‡ºæ•ˆæœ
        const audio = this.currentAudioSource
        const fadeOutDuration = 1000 // 1ç§’
        const startVolume = audio.volume
        const startTime = Date.now()

        const fadeInterval = setInterval(() => {
          const elapsed = Date.now() - startTime
          if (elapsed >= fadeOutDuration) {
            audio.volume = 0
            audio.pause()
            audio.src = ''
            clearInterval(fadeInterval)
            this.currentAudioSource = null
          } else {
            audio.volume = startVolume * (1 - elapsed / fadeOutDuration)
          }
        }, 50)
      } catch (error) {
        // å¿½ç•¥é”™è¯¯
        this.currentAudioSource = null
      }
    }
    // åœæ­¢ AudioBufferSourceNode
    else if (this.currentAudioSource instanceof AudioBufferSourceNode) {
      try {
        if (this.currentGainNode && this.audioContext) {
          // æ·¡å‡ºæ•ˆæœ
          this.currentGainNode.gain.linearRampToValueAtTime(
            0,
            this.audioContext.currentTime + 1
          )
          setTimeout(() => {
            try { 
              if (this.currentAudioSource instanceof AudioBufferSourceNode) {
                this.currentAudioSource.stop()
              }
            } catch { /* already stopped */ }
            this.currentAudioSource = null
            this.currentGainNode = null
          }, 1100)
        } else {
          try { 
            if (this.currentAudioSource instanceof AudioBufferSourceNode) {
              this.currentAudioSource.stop()
            }
          } catch { /* already stopped */ }
          this.currentAudioSource = null
        }
      } catch (error) {
        this.currentAudioSource = null
        this.currentGainNode = null
      }
    }

    // æ¸…ç† AudioContextï¼ˆå¦‚æœä¸å†éœ€è¦ï¼‰
    if (this.audioContext && !this.currentAudioSource) {
      try { 
        this.audioContext.close().catch(() => {}) 
      } catch { /* ignore */ }
      this.audioContext = null
    }
  }

  /**
   * è·å–å½“å‰é€‚é…é…ç½®
   */
  getCurrentAdaptation(): EnvironmentAdaptation | null {
    return this.currentAdaptation
  }
}

export const emotionAdapter = new EmotionAdapter()
