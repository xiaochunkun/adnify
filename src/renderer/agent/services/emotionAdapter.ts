/**
 * æƒ…ç»ªç¯å¢ƒé€‚é…æœåŠ¡
 * æ ¹æ®æƒ…ç»ªçŠ¶æ€è‡ªåŠ¨è°ƒæ•´ç¼–è¾‘å™¨ç¯å¢ƒ
 */

import { EventBus } from '../core/EventBus'
import { logger } from '@utils/Logger'
import type {
  EmotionState,
  EmotionDetection,
  EnvironmentAdaptation,
} from '../types/emotion'

// é»˜è®¤é€‚é…é…ç½®
const DEFAULT_ADAPTATIONS: Record<EmotionState, EnvironmentAdaptation> = {
  focused: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#3b82f6',
    },
    ui: {
      notifications: 'minimal',
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'suggestive',
      tone: 'neutral',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: false,
      volume: 0,
      type: 'none',
    },
    break: {
      suggestBreak: false,
      breakInterval: 90 * 60 * 1000, // 90åˆ†é’Ÿ
      microBreaks: false,
    },
  },
  
  frustrated: {
    theme: {
      id: 'adnify-dark',
      brightness: 'dim',
      accentColor: '#f97316', // æ¸©æš–çš„æ©™è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 15, // ç¨å¤§å­—ä½“å‡å°‘å‹åŠ›
      lineHeight: 1.6,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'high',
    },
    sound: {
      enabled: true,
      volume: 0.3,
      type: 'relax',
    },
    break: {
      suggestBreak: true,
      breakInterval: 15 * 60 * 1000, // 15åˆ†é’Ÿå»ºè®®ä¼‘æ¯
      microBreaks: true,
    },
  },
  
  tired: {
    theme: {
      id: 'adnify-dark',
      brightness: 'dim', // é™ä½äº®åº¦
      accentColor: '#8b5cf6', // æŸ”å’Œçš„ç´«è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 16, // æ›´å¤§å­—ä½“
      lineHeight: 1.7,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'low', // å‡å°‘å¹²æ‰°
    },
    sound: {
      enabled: true,
      volume: 0.2,
      type: 'energize',
    },
    break: {
      suggestBreak: true,
      breakInterval: 30 * 60 * 1000, // 30åˆ†é’Ÿ
      microBreaks: true,
    },
  },
  
  excited: {
    theme: {
      id: 'adnify-dark',
      brightness: 'bright',
      accentColor: '#22c55e', // æ˜äº®çš„ç»¿è‰²
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'fast',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'passive', // ä¸æ‰“æ‰°åˆ›æ„
      tone: 'neutral',
      suggestionFrequency: 'low',
    },
    sound: {
      enabled: true,
      volume: 0.4,
      type: 'focus',
    },
    break: {
      suggestBreak: false,
      breakInterval: 120 * 60 * 1000,
      microBreaks: false,
    },
  },
  
  bored: {
    theme: {
      id: 'cyberpunk',
      brightness: 'bright',
      accentColor: '#ec4899', // é²œè‰³çš„ç²‰è‰²
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'fast',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'active',
      tone: 'encouraging',
      suggestionFrequency: 'high', // å¤šç»™å»ºè®®
    },
    sound: {
      enabled: true,
      volume: 0.5,
      type: 'energize',
    },
    break: {
      suggestBreak: true,
      breakInterval: 45 * 60 * 1000,
      microBreaks: true,
    },
  },
  
  stressed: {
    theme: {
      id: 'midnight',
      brightness: 'dim',
      accentColor: '#06b6d4', // å†·é™çš„é’è‰²
    },
    ui: {
      notifications: 'disabled',
      animationSpeed: 'slow',
      fontSize: 15,
      lineHeight: 1.6,
    },
    ai: {
      proactivity: 'active',
      tone: 'direct',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: true,
      volume: 0.25,
      type: 'relax',
    },
    break: {
      suggestBreak: true,
      breakInterval: 20 * 60 * 1000,
      microBreaks: true,
    },
  },
  
  flow: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#6366f1', // é›è“
    },
    ui: {
      notifications: 'disabled', // å®Œå…¨æ— å¹²æ‰°
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'passive', // ç»ä¸æ‰“æ‰°
      tone: 'neutral',
      suggestionFrequency: 'low',
    },
    sound: {
      enabled: true,
      volume: 0.3,
      type: 'focus',
    },
    break: {
      suggestBreak: false, // ä¸æ‰“æ‰°å¿ƒæµ
      breakInterval: 150 * 60 * 1000, // 2.5å°æ—¶
      microBreaks: true, // ä½†å»ºè®®å¾®ä¼‘æ¯
    },
  },
  
  neutral: {
    theme: {
      id: 'adnify-dark',
      brightness: 'normal',
      accentColor: '#3b82f6',
    },
    ui: {
      notifications: 'normal',
      animationSpeed: 'normal',
      fontSize: 14,
      lineHeight: 1.5,
    },
    ai: {
      proactivity: 'suggestive',
      tone: 'neutral',
      suggestionFrequency: 'medium',
    },
    sound: {
      enabled: false,
      volume: 0,
      type: 'none',
    },
    break: {
      suggestBreak: true,
      breakInterval: 60 * 60 * 1000,
      microBreaks: true,
    },
  },
}

// æƒ…ç»ªå¯¹åº”çš„æç¤ºæ¶ˆæ¯
const EMOTION_MESSAGES: Record<EmotionState, string[]> = {
  focused: [
    'ä¿æŒä¸“æ³¨ï¼Œä½ æ­£åœ¨é«˜æ•ˆå·¥ä½œ ğŸ’ª',
    'è‰¯å¥½çš„èŠ‚å¥ï¼Œç»§ç»­ä¿æŒ',
    'ä¸“æ³¨æ¨¡å¼å·²å¯åŠ¨',
  ],
  frustrated: [
    'é‡åˆ°å›°éš¾äº†å—ï¼Ÿæ·±å‘¼å¸ï¼Œä¸€æ­¥æ­¥æ¥ ğŸŒ±',
    'æ¯ä¸ª bug éƒ½æ˜¯æˆé•¿çš„æœºä¼š',
    'éœ€è¦æˆ‘å¸®ä½ åˆ†æä¸€ä¸‹å—ï¼Ÿ',
    'ä¼‘æ¯ä¸€ä¸‹ï¼Œæ¢ä¸ªæ€è·¯å¯èƒ½ä¼šæ›´å¥½',
  ],
  tired: [
    'çœ‹èµ·æ¥æœ‰ç‚¹ç´¯äº†ï¼Œå–æ¯æ°´ä¼‘æ¯ä¸€ä¸‹å§ â˜•',
    'é•¿æ—¶é—´å·¥ä½œä¼šé™ä½æ•ˆç‡ï¼Œå»ºè®®ä¼‘æ¯',
    'ä½ çš„çœ¼ç›éœ€è¦æ”¾æ¾äº†ï¼Œçœ‹çœ‹è¿œå¤„',
  ],
  excited: [
    'å……æ»¡èƒ½é‡ï¼ä¿æŒè¿™ä¸ªçŠ¶æ€ ğŸš€',
    'çµæ„Ÿçˆ†å‘æ—¶åˆ»ï¼Œè®°å½•ä¸‹æ¥',
    'åˆ›é€ åŠ›æ»¡æ»¡ï¼Œç»§ç»­ä¿æŒï¼',
  ],
  bored: [
    'çœ‹èµ·æ¥æœ‰ç‚¹æ— èŠï¼Œè¯•è¯•é‡æ„è¿™æ®µä»£ç ï¼Ÿ ğŸ¤”',
    'è¦ä¸è¦å°è¯•ä¸€ä¸ªæ–°çš„å®ç°æ–¹å¼ï¼Ÿ',
    'ä¼‘æ¯ä¸€ä¸‹ï¼Œåšç‚¹æœ‰è¶£çš„äº‹æƒ…',
  ],
  stressed: [
    'å‹åŠ›æœ‰ç‚¹å¤§ï¼Œæ·±å‘¼å¸æ”¾æ¾ä¸€ä¸‹ ğŸ§˜',
    'ä¼˜å…ˆçº§æ’åºï¼Œä¸€ä»¶ä¸€ä»¶æ¥',
    'ä½ å·²ç»åšå¾—å¾ˆå¥½äº†ï¼Œä¸è¦ç»™è‡ªå·±å¤ªå¤§å‹åŠ›',
    'éœ€è¦æˆ‘å¸®ä½ æ•´ç†ä¸€ä¸‹æ€è·¯å—ï¼Ÿ',
  ],
  flow: [
    'è¿›å…¥å¿ƒæµçŠ¶æ€ï¼Œäº«å—ç¼–ç çš„ä¹è¶£ âœ¨',
    'å®Œç¾çš„å¿ƒæµï¼Œç»§ç»­ä¿æŒ',
    'ä½ æ­£åœ¨åˆ›é€ ä¼Ÿå¤§çš„ä»£ç ',
  ],
  neutral: [],
}

class EmotionAdapter {
  private currentAdaptation: EnvironmentAdaptation | null = null
  private breakTimer: NodeJS.Timeout | null = null
  private microBreakTimer: NodeJS.Timeout | null = null
  private audioContext: AudioContext | null = null
  private unsubscribeEmotionChanged: (() => void) | null = null

  /**
   * åˆå§‹åŒ–é€‚é…å™¨
   */
  initialize(): void {
    // è®¢é˜…æƒ…ç»ªå˜åŒ–äº‹ä»¶
    this.unsubscribeEmotionChanged = EventBus.on('emotion:changed', (event) => {
      if (event.emotion) {
        this.adaptToEmotion(event.emotion)
      }
    })

    logger.agent.info('[EmotionAdapter] Initialized')
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup(): void {
    // å–æ¶ˆäº‹ä»¶è®¢é˜…
    if (this.unsubscribeEmotionChanged) {
      this.unsubscribeEmotionChanged()
      this.unsubscribeEmotionChanged = null
    }

    // æ¸…ç†å®šæ—¶å™¨
    if (this.breakTimer) {
      clearInterval(this.breakTimer)
      this.breakTimer = null
    }
    if (this.microBreakTimer) {
      clearInterval(this.microBreakTimer)
      this.microBreakTimer = null
    }

    // åœæ­¢ç¯å¢ƒéŸ³
    this.stopAmbientSound()

    logger.agent.info('[EmotionAdapter] Cleaned up')
  }

  /**
   * æ ¹æ®æƒ…ç»ªé€‚é…ç¯å¢ƒ
   */
  adaptToEmotion(detection: EmotionDetection): void {
    const adaptation = DEFAULT_ADAPTATIONS[detection.state]
    this.currentAdaptation = adaptation

    // åº”ç”¨å„é¡¹é€‚é…
    this.applyThemeAdaptation(adaptation.theme)
    this.applyUIAdaptation(adaptation.ui)
    this.applyAIAdaptation(adaptation.ai, detection.state)
    this.applySoundAdaptation(adaptation.sound)
    this.setupBreakReminders(adaptation.break, detection.state)

    // æ˜¾ç¤ºæƒ…ç»ªæ„ŸçŸ¥æç¤º
    this.showEmotionAwareness(detection)

    logger.agent.info('[EmotionAdapter] Adapted to:', detection.state)
  }

  /**
   * æ‰‹åŠ¨åº”ç”¨ç‰¹å®šæƒ…ç»ªçš„é€‚é…
   */
  forceAdapt(state: EmotionState): void {
    const mockDetection: EmotionDetection = {
      state,
      intensity: 0.8,
      confidence: 1,
      triggeredAt: Date.now(),
      duration: 0,
      factors: [],
    }
    this.adaptToEmotion(mockDetection)
  }

  // ===== ç§æœ‰é€‚é…æ–¹æ³• =====

  private applyThemeAdaptation(theme: EnvironmentAdaptation['theme']): void {
    // åˆ‡æ¢ä¸»é¢˜ï¼ˆç®€åŒ–å®ç°ï¼‰
    // const store = useStore.getState()

    // åº”ç”¨äº®åº¦è°ƒæ•´ï¼ˆé€šè¿‡ CSS å˜é‡ï¼‰
    const root = document.documentElement
    const brightnessMap = {
      dim: '0.85',
      normal: '1',
      bright: '1.1',
    }
    root.style.setProperty('--editor-brightness', brightnessMap[theme.brightness])
    
    // è®¾ç½®å¼ºè°ƒè‰²
    root.style.setProperty('--custom-accent', theme.accentColor)
  }

  private applyUIAdaptation(ui: EnvironmentAdaptation['ui']): void {
    // å­—ä½“å¤§å°ï¼ˆç®€åŒ–å®ç°ï¼‰
    // const store = useStore.getState()

    // åŠ¨ç”»é€Ÿåº¦ï¼ˆé€šè¿‡ CSS å˜é‡ï¼‰
    const root = document.documentElement
    const speedMap = {
      slow: '0.5s',
      normal: '0.2s',
      fast: '0.1s',
    }
    root.style.setProperty('--transition-duration', speedMap[ui.animationSpeed])

    // é€šçŸ¥è®¾ç½®ï¼ˆç®€åŒ–å®ç°ï¼‰
    // store.updateSettings?.({
    //   notifications: ui.notifications,
    // })
  }

  private applyAIAdaptation(
    _ai: EnvironmentAdaptation['ai'],
    state: EmotionState
  ): void {
    // æ›´æ–° AI é…ç½®ï¼ˆç®€åŒ–å®ç°ï¼‰
    // æœªæ¥å¯ä»¥åœ¨è¿™é‡Œæ ¹æ® ai.proactivity, ai.tone, ai.suggestionFrequency è°ƒæ•´ AI è¡Œä¸º
    // const aiConfig = { proactivity, tone, suggestionFrequency }

    // å‘é€æƒ…ç»ªæ„ŸçŸ¥æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯éœ€è¦é¼“åŠ±çš„çŠ¶æ€ï¼‰
    if (state !== 'neutral' && state !== 'flow') {
      const messages = EMOTION_MESSAGES[state]
      if (messages.length > 0) {
        // éšæœºé€‰æ‹©ä¸€æ¡æ¶ˆæ¯ï¼Œé¿å…é‡å¤
        const randomIndex = Math.floor(Math.random() * messages.length)
        const message = messages[randomIndex]
        
        // å»¶è¿Ÿæ˜¾ç¤ºï¼Œé¿å…æ‰“æ–­å·¥ä½œ
        setTimeout(() => {
          EventBus.emit({
            type: 'emotion:message',
            message,
            state,
          })
        }, 3000)
      }
    }
  }

  private applySoundAdaptation(sound: EnvironmentAdaptation['sound']): void {
    if (!sound.enabled || !sound.type || sound.type === 'none') {
      this.stopAmbientSound()
      return
    }

    // æ’­æ”¾ç¯å¢ƒéŸ³ï¼ˆå¦‚æœéœ€è¦ï¼‰
    this.playAmbientSound(sound.type, sound.volume)
  }

  private setupBreakReminders(
    breakConfig: EnvironmentAdaptation['break'],
    state: EmotionState
  ): void {
    // æ¸…é™¤ä¹‹å‰çš„è®¡æ—¶å™¨
    if (this.breakTimer) {
      clearInterval(this.breakTimer)
      this.breakTimer = null
    }
    if (this.microBreakTimer) {
      clearInterval(this.microBreakTimer)
      this.microBreakTimer = null
    }

    if (!breakConfig.suggestBreak) return

    // è®¾ç½®å¾®ä¼‘æ¯æé†’ï¼ˆæ¯20åˆ†é’Ÿï¼‰
    if (breakConfig.microBreaks) {
      this.microBreakTimer = setInterval(() => {
        EventBus.emit({
          type: 'break:micro',
          message: 'çœ¼ç›ç–²åŠ³äº†å—ï¼Ÿçœ‹çœ‹è¿œå¤„20ç§’ ğŸ‘€',
        })
      }, 20 * 60 * 1000)
    }

    // è®¾ç½®æ­£å¼ä¼‘æ¯æé†’
    this.breakTimer = setInterval(() => {
      const messages: Record<EmotionState, string> = {
        focused: 'ä½ å·²ç»ä¸“æ³¨å·¥ä½œå¾ˆä¹…äº†ï¼Œèµ·æ¥æ´»åŠ¨ä¸€ä¸‹å§ ğŸš¶',
        frustrated: 'å¡ä½äº†ï¼Ÿä¼‘æ¯ä¸€ä¸‹å¯èƒ½ä¼šæœ‰æ–°æ€è·¯ ğŸ’¡',
        tired: 'è¯¥ä¼‘æ¯ä¸€ä¸‹äº†ï¼Œå……ç”µåæ•ˆç‡ä¼šæ›´é«˜ âš¡',
        excited: 'ä¿æŒçƒ­æƒ…çš„åŒæ—¶ä¹Ÿè¦æ³¨æ„ä¼‘æ¯å“¦ â˜•',
        bored: 'ä¼‘æ¯ä¸€ä¸‹å§ï¼Œåšç‚¹æœ‰è¶£çš„äº‹æƒ… ğŸ®',
        stressed: 'å‹åŠ›å¤§æ—¶æ›´è¦ä¼‘æ¯ï¼Œæ·±å‘¼å¸æ”¾æ¾ä¸€ä¸‹ ğŸ§˜',
        flow: 'å¿ƒæµå¾ˆç¾å¥½ï¼Œä½†ä¹Ÿè®°å¾—ç…§é¡¾å¥½èº«ä½“ ğŸŒ¿',
        neutral: 'å·¥ä½œä¸€æ®µæ—¶é—´äº†ï¼Œä¼‘æ¯ä¸€ä¸‹å§ â˜•',
      }

      // ä¼‘æ¯å»ºè®®
      EventBus.emit({
        type: 'break:suggested',
        message: messages[state],
      })
    }, breakConfig.breakInterval)
  }

  private showEmotionAwareness(detection: EmotionDetection): void {
    // é€šè¿‡ toast æˆ–å†…è”æç¤ºæ˜¾ç¤ºæƒ…ç»ªæ£€æµ‹
    const emotionLabels: Record<EmotionState, string> = {
      focused: 'ä¸“æ³¨æ¨¡å¼',
      frustrated: 'æ£€æµ‹åˆ°æ²®ä¸§',
      tired: 'æ£€æµ‹åˆ°ç–²åŠ³',
      excited: 'èƒ½é‡æ»¡æ»¡',
      bored: 'æ£€æµ‹åˆ°æ— èŠ',
      stressed: 'æ£€æµ‹åˆ°å‹åŠ›',
      flow: 'å¿ƒæµçŠ¶æ€',
      neutral: 'å·¥ä½œæ¨¡å¼',
    }

    // ç®€åŒ– toast æç¤º
    console.log(`[Emotion] ${emotionLabels[detection.state]} - å¼ºåº¦: ${Math.round(detection.intensity * 100)}%`)
  }

  // è·å–æƒ…ç»ªå¯¹åº”çš„ toast ç±»å‹
  // private getEmotionVariant(state: EmotionState): string {...}

  // ===== ç¯å¢ƒéŸ³æ•ˆ =====

  private async playAmbientSound(
    type: 'focus' | 'relax' | 'energize' | 'none',
    volume: number
  ): Promise<void> {
    if (!type || type === 'none') {
      this.stopAmbientSound()
      return
    }

    // ç®€åŒ–çš„ç¯å¢ƒéŸ³æ•ˆå®ç°
    // å®é™…é¡¹ç›®ä¸­å¯ä»¥é›†æˆ Tone.js æˆ–å…¶ä»–éŸ³é¢‘åº“
    try {
      if (!this.audioContext) {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      }

      // åˆ›å»ºç®€å•çš„èƒŒæ™¯éŸ³
      const oscillator = this.audioContext.createOscillator()
      const gainNode = this.audioContext.createGain()

      // æ ¹æ®ç±»å‹è®¾ç½®ä¸åŒé¢‘ç‡
      const frequencies: Record<string, number> = {
        focus: 432, // 432Hz è¢«è®¤ä¸ºæœ‰åŠ©äºä¸“æ³¨
        relax: 528, // 528Hz æ”¾æ¾
        energize: 639, // 639Hz èƒ½é‡
      }

      oscillator.frequency.value = frequencies[type] || 432
      oscillator.type = 'sine'
      
      gainNode.gain.value = volume * 0.1 // å¾ˆä½çš„éŸ³é‡

      oscillator.connect(gainNode)
      gainNode.connect(this.audioContext.destination)

      oscillator.start()

      // 5åˆ†é’Ÿåè‡ªåŠ¨åœæ­¢
      setTimeout(() => {
        oscillator.stop()
      }, 5 * 60 * 1000)

    } catch (error) {
      logger.agent.error('[EmotionAdapter] Failed to play sound:', error)
    }
  }

  private stopAmbientSound(): void {
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
  }

  /**
   * è·å–å½“å‰é€‚é…é…ç½®
   */
  getCurrentAdaptation(): EnvironmentAdaptation | null {
    return this.currentAdaptation
  }
}

export const emotionAdapter = new EmotionAdapter()
